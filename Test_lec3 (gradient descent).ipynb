{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before =>  4 4.0\n",
      "\tgrad:  1.0 2.0 -2.0\n",
      "\tgrad:  2.0 4.0 -7.84\n",
      "\tgrad:  3.0 6.0 -16.2288\n",
      "progress: 0 w= 1.260688  cost= 4.919240100095999\n",
      "\tgrad:  1.0 2.0 -1.478624\n",
      "\tgrad:  2.0 4.0 -5.796206079999999\n",
      "\tgrad:  3.0 6.0 -11.998146585599997\n",
      "progress: 1 w= 1.453417766656  cost= 2.688769240265834\n",
      "\tgrad:  1.0 2.0 -1.093164466688\n",
      "\tgrad:  2.0 4.0 -4.285204709416961\n",
      "\tgrad:  3.0 6.0 -8.87037374849311\n",
      "progress: 2 w= 1.5959051959019805  cost= 1.4696334962911515\n",
      "\tgrad:  1.0 2.0 -0.8081896081960389\n",
      "\tgrad:  2.0 4.0 -3.1681032641284723\n",
      "\tgrad:  3.0 6.0 -6.557973756745939\n",
      "progress: 3 w= 1.701247862192685  cost= 0.8032755585999681\n",
      "\tgrad:  1.0 2.0 -0.59750427561463\n",
      "\tgrad:  2.0 4.0 -2.3422167604093502\n",
      "\tgrad:  3.0 6.0 -4.848388694047353\n",
      "progress: 4 w= 1.7791289594933983  cost= 0.43905614881022015\n",
      "\tgrad:  1.0 2.0 -0.44174208101320334\n",
      "\tgrad:  2.0 4.0 -1.7316289575717576\n",
      "\tgrad:  3.0 6.0 -3.584471942173538\n",
      "progress: 5 w= 1.836707389300983  cost= 0.2399802903801062\n",
      "\tgrad:  1.0 2.0 -0.3265852213980338\n",
      "\tgrad:  2.0 4.0 -1.2802140678802925\n",
      "\tgrad:  3.0 6.0 -2.650043120512205\n",
      "progress: 6 w= 1.8792758133988885  cost= 0.1311689630744999\n",
      "\tgrad:  1.0 2.0 -0.241448373202223\n",
      "\tgrad:  2.0 4.0 -0.946477622952715\n",
      "\tgrad:  3.0 6.0 -1.9592086795121197\n",
      "progress: 7 w= 1.910747160155559  cost= 0.07169462478267678\n",
      "\tgrad:  1.0 2.0 -0.17850567968888198\n",
      "\tgrad:  2.0 4.0 -0.6997422643804168\n",
      "\tgrad:  3.0 6.0 -1.4484664872674653\n",
      "progress: 8 w= 1.9340143044689266  cost= 0.03918700813247573\n",
      "\tgrad:  1.0 2.0 -0.13197139106214673\n",
      "\tgrad:  2.0 4.0 -0.5173278529636143\n",
      "\tgrad:  3.0 6.0 -1.0708686556346834\n",
      "progress: 9 w= 1.9512159834655312  cost= 0.021418922423117836\n",
      "after =>  4 7.804863933862125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x_data = [1.0,2.0,3.0]\n",
    "y_data = [2.0,4.0,6.0]\n",
    "\n",
    "data_size = 3\n",
    "alpha = 0.01\n",
    "w = 1.0\n",
    "\n",
    "def h(x): #hypothesis function\n",
    "    return x * w;\n",
    "\n",
    "def cost(x , y): #cost function\n",
    "    y_pred = h(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "def grad(x ,y):\n",
    "    return 2 * x * (x * w - y)\n",
    "\n",
    "#before training\n",
    "print(\"before => \" , 4 , h(4))\n",
    "\n",
    "#training loop\n",
    "for epoch in range(10) :\n",
    "    for x_val,y_val in zip(x_data,y_data):\n",
    "        gradient = grad(x_val, y_val)\n",
    "        w = w - alpha*gradient\n",
    "        print(\"\\tgrad: \",x_val, y_val, gradient)\n",
    "        l = cost(x_val, y_val)\n",
    "    print(\"progress:\",epoch , \"w=\", w,\" cost=\", l)\n",
    "\n",
    "#after training\n",
    "print(\"after => \" ,4 ,h(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
